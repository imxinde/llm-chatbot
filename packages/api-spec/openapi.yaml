openapi: 3.0.3
info:
  title: LLM Chatbot API
  description: API for LLM Chatbot application using OpenRouter
  version: 1.0.0
  contact:
    name: API Support

servers:
  - url: http://localhost:3000
    description: Development server
  - url: /
    description: Production server (relative)

paths:
  /api/chat:
    post:
      operationId: sendChatMessage
      summary: Send a chat message and receive streaming response
      description: |
        Sends messages to the LLM and receives a streaming response via Server-Sent Events (SSE).
        The response is streamed as multiple `data:` events, with the final event being `data: [DONE]`.
      tags:
        - Chat
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatRequest'
      responses:
        '200':
          description: Streaming response via SSE
          content:
            text/event-stream:
              schema:
                type: string
                description: |
                  Server-Sent Events stream. Each event contains:
                  - `data: {"content": "..."}` for content chunks
                  - `data: {"error": "..."}` for errors
                  - `data: [DONE]` when complete
        '400':
          description: Bad request - missing or invalid parameters
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'

  /api/models:
    get:
      operationId: getModels
      summary: Get available LLM models
      description: Returns a list of available models from OpenRouter
      tags:
        - Models
      responses:
        '200':
          description: List of available models
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelsResponse'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'

components:
  schemas:
    Message:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum:
            - user
            - assistant
            - system
          description: The role of the message author
        content:
          type: string
          description: The content of the message

    ChatRequest:
      type: object
      required:
        - messages
      properties:
        messages:
          type: array
          items:
            $ref: '#/components/schemas/Message'
          minItems: 1
          description: Array of messages in the conversation
        model:
          type: string
          default: openai/gpt-3.5-turbo
          description: The model ID to use for the response
          example: openai/gpt-3.5-turbo

    Model:
      type: object
      required:
        - id
        - name
      properties:
        id:
          type: string
          description: Unique identifier for the model
          example: openai/gpt-3.5-turbo
        name:
          type: string
          description: Human-readable name of the model
          example: GPT-3.5 Turbo
        description:
          type: string
          description: Description of the model capabilities
        context_length:
          type: integer
          description: Maximum context length in tokens
          example: 16385

    ModelsResponse:
      type: object
      required:
        - models
      properties:
        models:
          type: array
          items:
            $ref: '#/components/schemas/Model'
          description: Array of available models

    ErrorResponse:
      type: object
      required:
        - error
      properties:
        error:
          type: string
          description: Error message describing what went wrong
